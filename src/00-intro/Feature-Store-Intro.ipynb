{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076a7f63",
   "metadata": {},
   "source": [
    "## Feature Store Basics\n",
    "\n",
    "This notebook introduces the basics of working with the Hopsworks API and Pandas DataFrames.\n",
    "\n",
    "First, we will define a Pandas DataFrame with 4 credit card transactions in 3 different cities with the same credit card. The last 2 credit card transactions are labeled as 'fraud', while the first 2 transactions are labeled as 'not fraud'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9411b6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>trans_datetime</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-01 08:44:00</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 19:44:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:44:00</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_card_number      trans_datetime  amount        location  fraud\n",
       "0  1111 2222 3333 4444 2022-01-01 08:44:00  142.34       Sao Paolo  False\n",
       "1  1111 2222 3333 4444 2022-01-02 19:44:00   12.34  Rio De Janeiro  False\n",
       "2  1111 2222 3333 4444 2022-01-02 20:44:00   66.29       Stockholm   True\n",
       "3  1111 2222 3333 4444 2022-01-02 20:55:00  112.33       Stockholm   True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { \n",
    "    'credit_card_number': ['1111 2222 3333 4444', '1111 2222 3333 4444','1111 2222 3333 4444',\n",
    "                           '1111 2222 3333 4444'],\n",
    "    'trans_datetime': ['2022-01-01 08:44', '2022-01-02 19:44', '2022-01-02 20:44', '2022-01-02 20:55'],\n",
    "    'amount': [142.34, 12.34, 66.29, 112.33],\n",
    "    'location': ['Sao Paolo', 'Rio De Janeiro', 'Stockholm', 'Stockholm'],\n",
    "    'fraud': [False, False, True, True] \n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df['trans_datetime']= pd.to_datetime(df['trans_datetime'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5e1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e9f2d",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks\n",
    "\n",
    "You need an API key to connect. First, login to Hopsworks, then run this code. It will provide a link to get your API key, that you then need to copy and paste into the text box that appears below this cell.\n",
    "\n",
    "It is good practice to save this API key somewhere safe so you don't have to create a new one every time you use Hopsworks. If you run this code on your laptop, a copy of the API key will be cached locally in this directory in a file with restricted permissions, so you don't have to always re-enter the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c855e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy your Api Key (first register/login): https://c.app.hopsworks.ai/account/api/generated\n",
      "\n",
      "Paste it here: ········\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "proj = hopsworks.login()\n",
    "fs = proj.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d38175",
   "metadata": {},
   "source": [
    "### Create a Feature Group\n",
    "\n",
    "A feature group is a table of features that are computed together in the same feature pipeline and written as a DataFrame to the Feature Store. You should have a unique idenitfier for each row that may be one or more columns, and you define as the `primary_key`. You may also have a column that represents the timestamp or datetime for when row values were observed. If so, you should specify the `event_time` column when creating the Feature Group.\n",
    "\n",
    "Hopsworks have comprehensive documentation on Feature Groups. Click on these links to learn more.\n",
    "\n",
    "* [Feature Group Concept](https://docs.hopsworks.ai/3.0/concepts/fs/feature_group/fg_overview/)\n",
    "* [Feature Group Creation Guide](https://docs.hopsworks.ai/3.0/user_guides/fs/feature_group/create/)\n",
    "* [Feature Group API Docs](https://docs.hopsworks.ai/feature-store-api/3.0/generated/api/feature_group_api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea7a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_transactions\",\n",
    "     version=1,\n",
    "     description=\"Credit Card Transaction data\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='trans_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c0972",
   "metadata": {},
   "source": [
    "### Write your DataFrame to the Feature Group\n",
    "When you write your DataFrame to the feature group, first the DataFrame is copied to Hopsworks. \n",
    "Then a backfill ingestion job is run on Hopsworks to insert/append the DataFrame to the Feature Group. \n",
    "The job is a Spark job, and the data is stored in a Apache Hudi table in Hopsworks.\n",
    "\n",
    "It will take about 1 minute for the ingestion job to complete.\n",
    "If you don't want to wait 1 minute, you make the ingestion job run in the background with:\n",
    "\n",
    "\n",
    "    fg.insert(df, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3380610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/4255/fs/4198/fg/5517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bb3cb7cb5f42838391e1869a83e845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/4 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/4255/jobs/named/credit_card_transactions_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fc5e0107c70>, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.insert(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2bc45",
   "metadata": {},
   "source": [
    "## Read using Feature Views\n",
    "\n",
    "When you want to use features to train or serve models, you create Feature that are `labels` View a Feature View by first selecting features from Feature Groups. Here, we only have 1 Feature Group, and we select 3 features from it, returning a `query` object. The `query` object defines the set of features (or schema) for a Feature View. \n",
    "\n",
    "You create a Feature View with a `query` object (specifying the features and any extra columns that might be needed for inference (but not training)), providing a name and version, and specifying the columns that are `labels`, that is, the target your machine learning algorithm will try and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7e3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/4255/fs/4198/fv/credit_card_transactions/version/1\n"
     ]
    }
   ],
   "source": [
    "query = fg.select([\"amount\", \"location\", \"fraud\"])\n",
    "\n",
    "fv = fs.create_feature_view(name=\"credit_card_transactions\",\n",
    "                            version=1,\n",
    "                            description=\"Features from the credit_card_transactions FG\",\n",
    "                            labels=[\"fraud\"],\n",
    "                            query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b2099",
   "metadata": {},
   "source": [
    "### Splitting into Train/Test sets\n",
    "\n",
    "With a Feature View, you can read train and test sets directly as Pandas DataFrames - similar to scikit-learn.\n",
    "Here, \n",
    "\n",
    "* `X_train` is the features of our train set, \n",
    "* `y_train` is the labels of our train set, \n",
    "* `X_test` is the features of our test set, \n",
    "* `y_test` is the labels of our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792da473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 09:49:15,975 INFO: USE `brando_featurestore`\n",
      "2022-11-10 09:49:16,969 INFO: SELECT `fg0`.`amount` `amount`, `fg0`.`location` `location`, `fg0`.`fraud` `fraud`\n",
      "FROM `brando_featurestore`.`credit_card_transactions_1` `fg0`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "VersionWarning: Incremented version to `1`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount   location\n",
       "0   66.29  Stockholm\n",
       "2  142.34  Sao Paolo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = fv.train_test_split(0.5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef54b2",
   "metadata": {},
   "source": [
    "### Saving training data as files\n",
    "Sometimes, if you have a large volume of training data, it is better to save training data as files. Then read the files in your training pipeline. You can create training data as CSV files that is randomly split into train/test sets as follows (the `td_version` is the version of the training data for this feature view, and you can track the progress of the job used to create the training data using the `td_job` object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578e424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/4255/jobs/named/credit_card_transactions_1_2_create_fv_td_10112022085116/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "td_version, td_job = fv.create_train_test_split(\n",
    "    description = 'Transactions fraud batch training dataset',\n",
    "    data_format = 'csv',\n",
    "    test_size = 0.5,\n",
    "    write_options = {'wait_for_job': True},\n",
    "    coalesce = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b958f",
   "metadata": {},
   "source": [
    "## Training Data as files\n",
    "The training data is now stored as a CSV file on Hopsworks under `Project Settings` -> `File Browser` -> <username>_Training_Datasets.\n",
    "    \n",
    "You can read the training data as split train/test sets with the following. Note the parameter `td_version` we pass here. A feature view can have many training datasets, so you need to supply the version you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e53364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount   location\n",
       "0  112.33  Stockholm"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = fv.get_train_test_split(td_version)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6d416",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Compute the total amount spent on the credit card by first grouping all the rows together with the same `credit_card_number` and then summing up their amounts. \n",
    "\n",
    "The code first creates a new DataFrame with only the `credit_card_number` and `amount` columns, then the logic of a group-by could be described as \n",
    "\n",
    "    for-each (`credit_card_number`) do \\sigma amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4be1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 1111 2222 3333 4444 to 1111 2222 3333 4444\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   total_spent  1 non-null      float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 16.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df2 = df[[\"credit_card_number\", \"amount\"]].groupby(\"credit_card_number\").sum()\n",
    "df2.rename(columns={\"amount\": \"total_spent\"}, inplace=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be0be838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_spent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_card_number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111 2222 3333 4444</th>\n",
       "      <td>333.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     total_spent\n",
       "credit_card_number              \n",
       "1111 2222 3333 4444        333.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187468e",
   "metadata": {},
   "source": [
    " We might also want to know at what point-in-time was that total and add a column with the datetime of the last (most recent) credit card transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04244e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_spent</th>\n",
       "      <th>as_of_datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_card_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111 2222 3333 4444</th>\n",
       "      <td>333.3</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     total_spent      as_of_datetime\n",
       "credit_card_number                                  \n",
       "1111 2222 3333 4444        333.3 2022-01-02 20:55:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"as_of_datetime\"] = df[[\"credit_card_number\", \"trans_datetime\"]].groupby(\"credit_card_number\").max()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27a872",
   "metadata": {},
   "source": [
    "The `groupby` operation sets `credit_card_number` as the index of our DataFrame.\n",
    "We want `credit_card_number` as a column, as Pandas indexes are not written to the Feature Group.\n",
    "We can move the index to a column using `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec0104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>as_of_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>333.3</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_card_number  total_spent      as_of_datetime\n",
       "0  1111 2222 3333 4444        333.3 2022-01-02 20:55:00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.reset_index(inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8253595",
   "metadata": {},
   "source": [
    "We create a feature group to store the contents of `df2` with our aggregated credit card spending information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c321ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg2 = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_spending\",\n",
    "     version=1,\n",
    "     description=\"Credit Card Spending\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='as_of_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712f283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/4255/fs/4198/fg/5519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb60377d071439c9ecdc3b14257401b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/4255/jobs/named/credit_card_spending_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fc5c805ed00>, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg2.insert(df2, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7aedf",
   "metadata": {},
   "source": [
    "Let's add some more data to our original feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac3a4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0aad28032a04890aec075f78ffa6e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/4 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/4255/jobs/named/credit_card_transactions_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fc5e0127220>, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data = { \n",
    "    'credit_card_number': ['9999 8888 7777 6666', '9999 8888 7777 6666','9999 8888 7777 6666',\n",
    "                           '9999 8888 7777 6666'],\n",
    "    'trans_datetime': ['2022-01-02 04:11', '2022-01-03 07:24', '2022-01-05 10:33', '2022-01-05 11:50'],\n",
    "    'amount': [55.67, 84, 77.95, 183],\n",
    "    'location': ['San Francisco', 'San Francisco', 'Dublin', 'Dublin'],\n",
    "    'fraud': [False, False, False, False] \n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(more_data)\n",
    "df3['trans_datetime']= pd.to_datetime(df3['trans_datetime'])\n",
    "\n",
    "fg = fs.get_feature_group(name=\"credit_card_transactions\", version=1)\n",
    "\n",
    "fg.insert(df3, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1d883",
   "metadata": {},
   "source": [
    "Now let's compute how much money was spent on the card since the last time we computed amount spent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2dc55",
   "metadata": {},
   "source": [
    "## Time Series: Window Aggregations\n",
    "\n",
    "Count the amount of money spent per day (make the length of the window '1d').\n",
    "We will need to set the `event_time` column as the index in order to use Pandas built-in window aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2baba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:04:39,813 INFO: USE `brando_featurestore`\n",
      "2022-11-10 10:04:40,845 INFO: SELECT `fg0`.`credit_card_number` `credit_card_number`, `fg0`.`trans_datetime` `trans_datetime`, `fg0`.`amount` `amount`, `fg0`.`location` `location`, `fg0`.`fraud` `fraud`\n",
      "FROM `brando_featurestore`.`credit_card_transactions_1` `fg0`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>trans_datetime</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:44:00</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-01 08:44:00</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 19:44:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>2022-01-03 07:24:00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>2022-01-05 10:33:00</td>\n",
       "      <td>77.95</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>2022-01-05 11:50:00</td>\n",
       "      <td>183.00</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>2022-01-02 04:11:00</td>\n",
       "      <td>55.67</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_card_number      trans_datetime  amount        location  fraud\n",
       "0  1111 2222 3333 4444 2022-01-02 20:44:00   66.29       Stockholm   True\n",
       "1  1111 2222 3333 4444 2022-01-02 20:55:00  112.33       Stockholm   True\n",
       "2  1111 2222 3333 4444 2022-01-01 08:44:00  142.34       Sao Paolo  False\n",
       "3  1111 2222 3333 4444 2022-01-02 19:44:00   12.34  Rio De Janeiro  False\n",
       "4  9999 8888 7777 6666 2022-01-03 07:24:00   84.00   San Francisco  False\n",
       "5  9999 8888 7777 6666 2022-01-05 10:33:00   77.95          Dublin  False\n",
       "6  9999 8888 7777 6666 2022-01-05 11:50:00  183.00          Dublin  False\n",
       "7  9999 8888 7777 6666 2022-01-02 04:11:00   55.67   San Francisco  False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = fg.read()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "864dc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.set_index('trans_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b325eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d51e0b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "      <th>rolling_max_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 04:11:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>55.67</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 19:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "      <td>55.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 20:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>66.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 20:55:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>112.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 07:24:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>84.00</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>112.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 10:33:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>77.95</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "      <td>77.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 11:50:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>183.00</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "      <td>183.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      credit_card_number  amount        location  fraud  \\\n",
       "trans_datetime                                                            \n",
       "2022-01-01 08:44:00  1111 2222 3333 4444  142.34       Sao Paolo  False   \n",
       "2022-01-02 04:11:00  9999 8888 7777 6666   55.67   San Francisco  False   \n",
       "2022-01-02 19:44:00  1111 2222 3333 4444   12.34  Rio De Janeiro  False   \n",
       "2022-01-02 20:44:00  1111 2222 3333 4444   66.29       Stockholm   True   \n",
       "2022-01-02 20:55:00  1111 2222 3333 4444  112.33       Stockholm   True   \n",
       "2022-01-03 07:24:00  9999 8888 7777 6666   84.00   San Francisco  False   \n",
       "2022-01-05 10:33:00  9999 8888 7777 6666   77.95          Dublin  False   \n",
       "2022-01-05 11:50:00  9999 8888 7777 6666  183.00          Dublin  False   \n",
       "\n",
       "                     rolling_max_1d  \n",
       "trans_datetime                       \n",
       "2022-01-01 08:44:00          142.34  \n",
       "2022-01-02 04:11:00          142.34  \n",
       "2022-01-02 19:44:00           55.67  \n",
       "2022-01-02 20:44:00           66.29  \n",
       "2022-01-02 20:55:00          112.33  \n",
       "2022-01-03 07:24:00          112.33  \n",
       "2022-01-05 10:33:00           77.95  \n",
       "2022-01-05 11:50:00          183.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df5['rolling_max_1d'] = df5.rolling('1D').amount.max()\n",
    "    df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dec426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "      <th>rolling_max_1d</th>\n",
       "      <th>rolling_mean_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "      <td>142.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 04:11:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>55.67</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "      <td>99.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 19:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "      <td>55.67</td>\n",
       "      <td>34.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 20:44:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>66.29</td>\n",
       "      <td>44.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 20:55:00</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>112.33</td>\n",
       "      <td>61.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 07:24:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>84.00</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>112.33</td>\n",
       "      <td>68.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 10:33:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>77.95</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "      <td>77.95</td>\n",
       "      <td>77.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 11:50:00</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>183.00</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>False</td>\n",
       "      <td>183.00</td>\n",
       "      <td>130.475000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      credit_card_number  amount        location  fraud  \\\n",
       "trans_datetime                                                            \n",
       "2022-01-01 08:44:00  1111 2222 3333 4444  142.34       Sao Paolo  False   \n",
       "2022-01-02 04:11:00  9999 8888 7777 6666   55.67   San Francisco  False   \n",
       "2022-01-02 19:44:00  1111 2222 3333 4444   12.34  Rio De Janeiro  False   \n",
       "2022-01-02 20:44:00  1111 2222 3333 4444   66.29       Stockholm   True   \n",
       "2022-01-02 20:55:00  1111 2222 3333 4444  112.33       Stockholm   True   \n",
       "2022-01-03 07:24:00  9999 8888 7777 6666   84.00   San Francisco  False   \n",
       "2022-01-05 10:33:00  9999 8888 7777 6666   77.95          Dublin  False   \n",
       "2022-01-05 11:50:00  9999 8888 7777 6666  183.00          Dublin  False   \n",
       "\n",
       "                     rolling_max_1d  rolling_mean_1d  \n",
       "trans_datetime                                        \n",
       "2022-01-01 08:44:00          142.34       142.340000  \n",
       "2022-01-02 04:11:00          142.34        99.005000  \n",
       "2022-01-02 19:44:00           55.67        34.005000  \n",
       "2022-01-02 20:44:00           66.29        44.766667  \n",
       "2022-01-02 20:55:00          112.33        61.657500  \n",
       "2022-01-03 07:24:00          112.33        68.740000  \n",
       "2022-01-05 10:33:00           77.95        77.950000  \n",
       "2022-01-05 11:50:00          183.00       130.475000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5['rolling_mean_1d'] = df5.rolling('1D').amount.mean()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "683a0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114b74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_agg = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_rolling_windows\",\n",
    "     version=1,\n",
    "     description=\"Daily Credit Card Spending\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='trans_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9b05b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/4255/fs/4198/fg/5521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc81ceebfce40938953048c9e61ffd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/8 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/4255/jobs/named/credit_card_rolling_windows_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fc5e0127be0>, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_agg.insert(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31174a83",
   "metadata": {},
   "source": [
    "### Create a Feature View using features from multiple Feature Groups\n",
    "\n",
    "We want to create a model that uses features from multiple feature groups. \n",
    "We will select features from the different feature groups and join them together to create a query object. \n",
    "We can read the data in the query object as a DataFrame to inspect it before we create the feature view. \n",
    "We will use the feature view to read the training data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faf25f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:07:29,294 INFO: USE `brando_featurestore`\n",
      "2022-11-10 10:07:30,300 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg1`.`credit_card_number` `credit_card_number`, `fg1`.`trans_datetime` `trans_datetime`, `fg1`.`amount` `amount`, `fg1`.`location` `location`, `fg1`.`fraud` `fraud`, `fg1`.`credit_card_number` `join_pk_credit_card_number`, `fg1`.`trans_datetime` `join_evt_trans_datetime`, `fg0`.`rolling_max_1d` `rolling_max_1d`, `fg0`.`rolling_mean_1d` `rolling_mean_1d`, RANK() OVER (PARTITION BY `fg0`.`credit_card_number`, `fg1`.`trans_datetime` ORDER BY `fg0`.`trans_datetime` DESC) pit_rank_hopsworks\n",
      "FROM `brando_featurestore`.`credit_card_transactions_1` `fg1`\n",
      "INNER JOIN `brando_featurestore`.`credit_card_rolling_windows_1` `fg0` ON `fg1`.`credit_card_number` = `fg0`.`credit_card_number` AND `fg1`.`trans_datetime` >= `fg0`.`trans_datetime`) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`credit_card_number` `credit_card_number`, `right_fg0`.`trans_datetime` `trans_datetime`, `right_fg0`.`amount` `amount`, `right_fg0`.`location` `location`, `right_fg0`.`fraud` `fraud`, `right_fg0`.`rolling_max_1d` `rolling_max_1d`, `right_fg0`.`rolling_mean_1d` `rolling_mean_1d`\n",
      "FROM right_fg0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>trans_datetime</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "      <th>rolling_max_1d</th>\n",
       "      <th>rolling_mean_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-01 08:44:00</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "      <td>142.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 19:44:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "      <td>55.67</td>\n",
       "      <td>34.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:44:00</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>66.29</td>\n",
       "      <td>44.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "      <td>112.33</td>\n",
       "      <td>61.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9999 8888 7777 6666</td>\n",
       "      <td>2022-01-02 04:11:00</td>\n",
       "      <td>55.67</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>False</td>\n",
       "      <td>142.34</td>\n",
       "      <td>99.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_card_number      trans_datetime  amount        location  fraud  \\\n",
       "0  1111 2222 3333 4444 2022-01-01 08:44:00  142.34       Sao Paolo  False   \n",
       "1  1111 2222 3333 4444 2022-01-02 19:44:00   12.34  Rio De Janeiro  False   \n",
       "2  1111 2222 3333 4444 2022-01-02 20:44:00   66.29       Stockholm   True   \n",
       "3  1111 2222 3333 4444 2022-01-02 20:55:00  112.33       Stockholm   True   \n",
       "4  9999 8888 7777 6666 2022-01-02 04:11:00   55.67   San Francisco  False   \n",
       "\n",
       "   rolling_max_1d  rolling_mean_1d  \n",
       "0          142.34       142.340000  \n",
       "1           55.67        34.005000  \n",
       "2           66.29        44.766667  \n",
       "3          112.33        61.657500  \n",
       "4          142.34        99.005000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = fg.select_all().join(fg_agg.select(['rolling_max_1d', 'rolling_mean_1d']))\n",
    "\n",
    "training_data = query.read()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caa4cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/4255/fs/4198/fv/credit_card_fraud_rolling/version/1\n"
     ]
    }
   ],
   "source": [
    "fv = fs.create_feature_view(name=\"credit_card_fraud_rolling\",\n",
    "                            description=\"Features for a model to predict credit card fraud, including rolling windows\",\n",
    "                            version=1,\n",
    "                            query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:10:48,919 INFO: USE `brando_featurestore`\n",
      "2022-11-10 10:10:50,016 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg1`.`credit_card_number` `credit_card_number`, `fg1`.`trans_datetime` `trans_datetime`, `fg1`.`amount` `amount`, `fg1`.`location` `location`, `fg1`.`fraud` `fraud`, `fg1`.`credit_card_number` `join_pk_credit_card_number`, `fg1`.`trans_datetime` `join_evt_trans_datetime`, `fg0`.`rolling_max_1d` `rolling_max_1d`, `fg0`.`rolling_mean_1d` `rolling_mean_1d`, RANK() OVER (PARTITION BY `fg1`.`credit_card_number`, `fg1`.`trans_datetime` ORDER BY `fg0`.`trans_datetime` DESC) pit_rank_hopsworks\n",
      "FROM `brando_featurestore`.`credit_card_transactions_1` `fg1`\n",
      "INNER JOIN `brando_featurestore`.`credit_card_rolling_windows_1` `fg0` ON `fg1`.`credit_card_number` = `fg0`.`credit_card_number` AND `fg1`.`trans_datetime` >= `fg0`.`trans_datetime`) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`credit_card_number` `credit_card_number`, `right_fg0`.`trans_datetime` `trans_datetime`, `right_fg0`.`amount` `amount`, `right_fg0`.`location` `location`, `right_fg0`.`fraud` `fraud`, `right_fg0`.`rolling_max_1d` `rolling_max_1d`, `right_fg0`.`rolling_mean_1d` `rolling_mean_1d`\n",
      "FROM right_fg0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = fv.train_test_split(0.5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7576002",
   "metadata": {},
   "source": [
    "### Read from Feature Groups\n",
    "\n",
    "You are also able to read data from Feature Groups as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1717fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = fs.get_feature_group(name=\"credit_card_transactions\", version=1)\n",
    "read_df = fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67029b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5aa606",
   "metadata": {},
   "source": [
    "### Filters\n",
    "You can use filters on the `query` object or on the Feature Groups, when reading from them. Here, we read all rows where the transaction amount is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs.feature import Feature\n",
    "\n",
    "big_amounts_df = fg.filter(Feature(\"amount\") > 100).read()\n",
    "big_amounts_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
